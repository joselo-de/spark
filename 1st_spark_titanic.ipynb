{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spark, let the system find it easily with findspark\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/hadoop/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('titanic_spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+-------+-----------+--------------------+-----+----------+-----+------+\n",
      "|row_names|pclass|survived|                name|    age|   embarked|           home_dest| room|    ticket| boat|   sex|\n",
      "+---------+------+--------+--------------------+-------+-----------+--------------------+-----+----------+-----+------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|29.0000|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|\n",
      "|        2|   1st|       0|Allison, Miss Hel...| 2.0000|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|30.0000|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|25.0000|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|\n",
      "|        5|   1st|       1|Allison, Master H...| 0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|47.0000|Southampton|        New York, NY| E-12|      null|    3|  male|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|63.0000|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|39.0000|Southampton|         Belfast, NI| A-36|      null| null|  male|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|58.0000|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|71.0000|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|\n",
      "+---------+------+--------+--------------------+-------+-----------+--------------------+-----+----------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read data source. format accepts 'json', 'csv', 'txt'\n",
    "df = spark.read.format('csv').option('header', 'True').option('inferSchema', 'True').load('data/titanic.csv')\n",
    "df.show(10)\n",
    "\n",
    "# example if dataset is on an S3 bucket\n",
    "# df = spark.read.csv('s3n://bigd-hadoop/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------+-------------------+--------------------+------------------+-----------+-------------------+------+------------------+-----------------+------+\n",
      "|summary|        row_names|pclass|           survived|                name|               age|   embarked|          home_dest|  room|            ticket|             boat|   sex|\n",
      "+-------+-----------------+------+-------------------+--------------------+------------------+-----------+-------------------+------+------------------+-----------------+------+\n",
      "|  count|             1313|  1313|               1313|                1313|              1313|        821|                754|    77|                69|              347|  1313|\n",
      "|   mean|            657.0|  null|  0.341964965727342|                null| 31.19418104265403|       null|               null|2131.0|          101216.5| 7.69620253164557|  null|\n",
      "| stddev|379.1747618183468|  null|0.47454867068071604|                null|14.747525275652208|       null|               null|   NaN|140047.94688015297|3.894871999310186|  null|\n",
      "|    min|                1|   1st|                  0|\"Brown, Mrs James...|            0.1667|  Cherbourg|      ?Havana, Cuba|  2131|                  |            (101)|female|\n",
      "|    max|             1313|   3rd|                  1|del Carlo, Mrs Se...|                NA|Southampton|Zurich, Switzerland|   F-?|            L15 1s|                D|  male|\n",
      "+-------+-----------------+------+-------------------+--------------------+------------------+-----------+-------------------+------+------------------+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we can take a quick look at the data with describe()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe rows:  1313\n",
      "columns:  11\n"
     ]
    }
   ],
   "source": [
    "# how many rows and columns?\n",
    "print('dataframe rows: ', df.count())\n",
    "print('columns: ', len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- row_names: integer (nullable = true)\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- home_dest: string (nullable = true)\n",
      " |-- room: string (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a look at the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the schema, the first thing we notice is that 'age' and 'class' are strings. We expected those to be numbers, so we need to transform them first.\n",
    "\n",
    "#### We will be showing the resulting dataframe everytime we make a tranformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|pclass|\n",
      "+------+\n",
      "|   2nd|\n",
      "|   1st|\n",
      "|   3rd|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find out the different classes\n",
    "df.select('pclass').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use UDF (User Defined Functions) to create class_index (string to number conversion)\n",
    "\n",
    "\n",
    "An example of UDF using the Lambda Function:\n",
    "\n",
    "age_udf = udf(lambda age: 'young' if age <= 30 else 'senior', StringType())\n",
    "\n",
    "df = df.withColumn('age_group', age_udf(df.age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+-------+-----------+--------------------+-----+----------+-----+------+-----------+\n",
      "|row_names|pclass|survived|                name|    age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|\n",
      "+---------+------+--------+--------------------+-------+-----------+--------------------+-----+----------+-----+------+-----------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|29.0000|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|\n",
      "|        2|   1st|       0|Allison, Miss Hel...| 2.0000|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|30.0000|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|25.0000|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|\n",
      "|        5|   1st|       1|Allison, Master H...| 0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|47.0000|Southampton|        New York, NY| E-12|      null|    3|  male|          1|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|63.0000|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|39.0000|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|58.0000|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|71.0000|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|\n",
      "+---------+------+--------+--------------------+-------+-----------+--------------------+-----+----------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, when, col\n",
    "from pyspark.sql.types import StringType, DoubleType, IntegerType, ByteType\n",
    "\n",
    "class_udf = udf(lambda pclass: 1 if pclass == '1st' else (2 if pclass == '2nd' else 3), IntegerType())\n",
    "df = df.withColumn('class_index', class_udf(df['pclass']))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|survived|\n",
      "+--------+\n",
      "|       1|\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# next column 'survived'. It looks good with only 0's and 1's\n",
    "df.select('survived').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|    age|count|\n",
      "+-------+-----+\n",
      "|     NA|  680|\n",
      "|30.0000|   28|\n",
      "|18.0000|   25|\n",
      "|22.0000|   23|\n",
      "|36.0000|   23|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupby 'age' just to find out how many NULL values do we have on that column\n",
    "df.groupBy('age').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- row_names: integer (nullable = true)\n",
      " |-- pclass: string (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- home_dest: string (nullable = true)\n",
      " |-- room: string (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- class_index: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transform 'age' from StringType to DoubleType\n",
    "df = df.withColumn('age', df['age'].cast(DoubleType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create age_imputed column before filling null values\n",
    "from pyspark.sql import functions as F\n",
    "df = df.select(col('*'), F.when(df['age'] > 0, 0).otherwise(1).alias('age_imputed'))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(format_number(avg(age), 2)='31.19')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean of 'age' to fill in the null values\n",
    "from pyspark.sql.functions import mean, format_number\n",
    "\n",
    "mean_age = df.select(format_number(mean(df['age']), 2)).collect()\n",
    "#mean_age = df.select(mean(df['age'])).collect()\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean_age as a float\n",
    "mean_age = float(mean_age[0][0])\n",
    "mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can fill the NULL values on 'age' with the mean_age\n",
    "# df = df.na.fill(mean_age, 'age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|new_age|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|   29.0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|    2.0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|   30.0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|   25.0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0| 0.9167|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|   47.0|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|   63.0|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|   39.0|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|   58.0|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|   71.0|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or better use Spark's imputer feature\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['age'], outputCols=['new_age'])\n",
    "model = imputer.fit(df)\n",
    "\n",
    "df = model.transform(df)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   embarked|count|\n",
      "+-----------+-----+\n",
      "|Southampton|  573|\n",
      "|       null|  492|\n",
      "|  Cherbourg|  203|\n",
      "| Queenstown|   45|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a look at 'embarked': 3 categories + null\n",
    "df.groupBy('embarked').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|new_age|embarked_index|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|   29.0|           0.0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|    2.0|           0.0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|   30.0|           0.0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|   25.0|           0.0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0| 0.9167|           0.0|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|   47.0|           0.0|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|   63.0|           0.0|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|   39.0|           0.0|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|   58.0|           0.0|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|   71.0|           1.0|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import libraries for indexer creation\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# we can either impute the NULL values with whatever arbitrary value we want or let spark do it.\n",
    "# here we use handleInvalid=\"keep\" to account for those NULL values. It will automatically create a 4th category with all the Nulls\n",
    "emb_indexer = StringIndexer(inputCol='embarked', outputCol='embarked_index', handleInvalid=\"keep\")\n",
    "df = emb_indexer.fit(df).transform(df)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|           home_dest|count|\n",
      "+--------------------+-----+\n",
      "|                null|  559|\n",
      "|        New York, NY|   65|\n",
      "|              London|   14|\n",
      "|        Montreal, PQ|   10|\n",
      "|Cornwall / Akron, OH|    9|\n",
      "|       Paris, France|    9|\n",
      "|Wiltshire, Englan...|    8|\n",
      "|        Winnipeg, MB|    8|\n",
      "|    Philadelphia, PA|    8|\n",
      "|             Belfast|    7|\n",
      "| Sweden Winnipeg, MN|    7|\n",
      "|        Brooklyn, NY|    7|\n",
      "|Rotherfield, Suss...|    5|\n",
      "|Sweden Worcester, MA|    5|\n",
      "|      Youngstown, OH|    5|\n",
      "|          Ottawa, ON|    5|\n",
      "|Haverford, PA / C...|    5|\n",
      "|Bulgaria Chicago, IL|    5|\n",
      "|Somerset / Bernar...|    5|\n",
      "|Guernsey / Elizab...|    4|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# although less nulls than other columns, the problem is lack of uniformity on home_dest.\n",
    "# this column will receive the same treatment as the 'name' column. we'll just drop it\n",
    "df.groupBy('home_dest').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    room|count|\n",
      "+--------+-----+\n",
      "|    null| 1236|\n",
      "|    F-33|    4|\n",
      "|   E-101|    3|\n",
      "|     C26|    3|\n",
      "|   C-101|    3|\n",
      "|B-51/3/5|    2|\n",
      "| B-58/60|    2|\n",
      "|    C-83|    2|\n",
      "|    C-93|    2|\n",
      "|   C-126|    2|\n",
      "|     B-5|    2|\n",
      "|    B-18|    2|\n",
      "|    C-87|    2|\n",
      "|    C-85|    2|\n",
      "|     D-?|    2|\n",
      "|   C-125|    2|\n",
      "|    D-35|    2|\n",
      "|     C22|    2|\n",
      "|    B-49|    2|\n",
      "|     C-7|    2|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in 'room' we see a lot of null values, but we can still get some categories if we take only the first letter\n",
    "df.groupBy('room').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|new_age|embarked_index|room_imputed|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|   29.0|           0.0|           0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|    2.0|           0.0|           0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|   30.0|           0.0|           0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|   25.0|           0.0|           0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0| 0.9167|           0.0|           0|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|   47.0|           0.0|           0|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|   63.0|           0.0|           0|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|   39.0|           0.0|           0|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|   58.0|           0.0|           0|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|   71.0|           1.0|           1|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create room_imputed column before filling nulls\n",
    "df = df.select(col('*'), F.when(df['room'].isNull(), 1).otherwise(0).alias('room_imputed'))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|new_age|embarked_index|room_imputed|room_categ|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|   29.0|           0.0|           0|         B|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|    2.0|           0.0|           0|         C|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|   30.0|           0.0|           0|         C|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|   25.0|           0.0|           0|         C|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0| 0.9167|           0.0|           0|         C|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|   47.0|           0.0|           0|         E|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|   63.0|           0.0|           0|         D|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|   39.0|           0.0|           0|         A|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|   58.0|           0.0|           0|         C|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|   71.0|           1.0|           1|      null|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create room_category taking the first letter from room_number\n",
    "from pyspark.sql.functions import col, substring\n",
    "df = df.select(col('*'), substring(col('room'), 0, 1).alias('room_categ'))\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|new_age|embarked_index|room_imputed|room_categ|room_index|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|   29.0|           0.0|           0|         B|       1.0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|    2.0|           0.0|           0|         C|       0.0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|   30.0|           0.0|           0|         C|       0.0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|   25.0|           0.0|           0|         C|       0.0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0| 0.9167|           0.0|           0|         C|       0.0|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|   47.0|           0.0|           0|         E|       3.0|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|   63.0|           0.0|           0|         D|       2.0|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|   39.0|           0.0|           0|         A|       5.0|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|   58.0|           0.0|           0|         C|       0.0|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|   71.0|           1.0|           1|      null|       7.0|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create index for room\n",
    "# we use again handleInvalid=\"keep\" to include null values in the index\n",
    "room_indexer = StringIndexer(inputCol='room_categ', outputCol='room_index', handleInvalid=\"keep\")\n",
    "df = room_indexer.fit(df).transform(df)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|           ticket|count|\n",
      "+-----------------+-----+\n",
      "|             null| 1244|\n",
      "| 17608 L262 7s 6d|    5|\n",
      "|       230136 L39|    4|\n",
      "|     13529 L26 5s|    3|\n",
      "|17754 L224 10s 6d|    3|\n",
      "|    28220 L32 10s|    3|\n",
      "|       230080 L26|    3|\n",
      "|       24160 L221|    3|\n",
      "|        13502 L77|    3|\n",
      "| 17582 L153 9s 3d|    3|\n",
      "|    17755 L512 6s|    2|\n",
      "|            17754|    2|\n",
      "|111361 L57 19s 7d|    2|\n",
      "|  36973 L83 9s 6d|    2|\n",
      "|17483 L221 15s 7d|    2|\n",
      "|           392091|    2|\n",
      "|            17483|    2|\n",
      "|       229236 L13|    1|\n",
      "|    17604 L39 12s|    1|\n",
      "| 17591 L50 9s 11d|    1|\n",
      "+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we'll drop 'ticket' too\n",
    "df.groupBy('ticket').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|boat|count|\n",
      "+----+-----+\n",
      "|null|  966|\n",
      "|   4|   27|\n",
      "|   5|   27|\n",
      "|   7|   22|\n",
      "|   3|   19|\n",
      "|   8|   18|\n",
      "|  11|   17|\n",
      "|   6|   17|\n",
      "|  13|   16|\n",
      "|   9|   15|\n",
      "|  14|   15|\n",
      "|  12|   13|\n",
      "|   2|   11|\n",
      "|   D|   10|\n",
      "|  10|    8|\n",
      "|   B|    6|\n",
      "|  15|    6|\n",
      "|   C|    6|\n",
      "|   A|    5|\n",
      "| 5/7|    4|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extracting some data from 'boat' looks really challenging. we can try just to index it\n",
    "df.groupBy('boat').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+----------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest| room|    ticket| boat|   sex|class_index|age_imputed|new_age|embarked_index|room_imputed|room_categ|room_index|boat_index|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+----------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO|  B-5|24160 L221|    2|female|          1|          0|   29.0|           0.0|           0|         B|       1.0|      11.0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|    2.0|           0.0|           0|         C|       0.0|      99.0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...|  C26|      null|(135)|  male|          1|          0|   30.0|           0.0|           0|         C|       0.0|      48.0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...|  C26|      null| null|female|          1|          0|   25.0|           0.0|           0|         C|       0.0|      99.0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...|  C22|      null|   11|  male|          1|          0| 0.9167|           0.0|           0|         C|       0.0|       5.0|\n",
      "|        6|   1st|       1|  Anderson, Mr Harry|  47.0|Southampton|        New York, NY| E-12|      null|    3|  male|          1|          0|   47.0|           0.0|           0|         E|       3.0|       3.0|\n",
      "|        7|   1st|       1|Andrews, Miss Kor...|  63.0|Southampton|          Hudson, NY|  D-7| 13502 L77|   10|female|          1|          0|   63.0|           0.0|           0|         D|       2.0|      13.0|\n",
      "|        8|   1st|       0|Andrews, Mr Thoma...|  39.0|Southampton|         Belfast, NI| A-36|      null| null|  male|          1|          0|   39.0|           0.0|           0|         A|       5.0|      99.0|\n",
      "|        9|   1st|       1|Appleton, Mrs Edw...|  58.0|Southampton| Bayside, Queens, NY|C-101|      null|    2|female|          1|          0|   58.0|           0.0|           0|         C|       0.0|      11.0|\n",
      "|       10|   1st|       0|Artagaveytia, Mr ...|  71.0|  Cherbourg| Montevideo, Uruguay| null|      null| (22)|  male|          1|          0|   71.0|           1.0|           1|      null|       7.0|      51.0|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+-----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create index for boat\n",
    "boat_indexer = StringIndexer(inputCol='boat', outputCol='boat_index', handleInvalid=\"keep\")\n",
    "df = boat_indexer.fit(df).transform(df)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   sex|count|\n",
      "+------+-----+\n",
      "|  male|  850|\n",
      "|female|  463|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# final column to transform: 'sex'\n",
    "df.groupBy('sex').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+--------+--------------------+------+-----------+--------------------+----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+----------+---------+\n",
      "|row_names|pclass|survived|                name|   age|   embarked|           home_dest|room|    ticket| boat|   sex|class_index|age_imputed|new_age|embarked_index|room_imputed|room_categ|room_index|boat_index|sex_index|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+----------+---------+\n",
      "|        1|   1st|       1|Allen, Miss Elisa...|  29.0|Southampton|        St Louis, MO| B-5|24160 L221|    2|female|          1|          0|   29.0|           0.0|           0|         B|       1.0|      11.0|      1.0|\n",
      "|        2|   1st|       0|Allison, Miss Hel...|   2.0|Southampton|Montreal, PQ / Ch...| C26|      null| null|female|          1|          0|    2.0|           0.0|           0|         C|       0.0|      99.0|      1.0|\n",
      "|        3|   1st|       0|Allison, Mr Hudso...|  30.0|Southampton|Montreal, PQ / Ch...| C26|      null|(135)|  male|          1|          0|   30.0|           0.0|           0|         C|       0.0|      48.0|      0.0|\n",
      "|        4|   1st|       0|Allison, Mrs Huds...|  25.0|Southampton|Montreal, PQ / Ch...| C26|      null| null|female|          1|          0|   25.0|           0.0|           0|         C|       0.0|      99.0|      1.0|\n",
      "|        5|   1st|       1|Allison, Master H...|0.9167|Southampton|Montreal, PQ / Ch...| C22|      null|   11|  male|          1|          0| 0.9167|           0.0|           0|         C|       0.0|       5.0|      0.0|\n",
      "+---------+------+--------+--------------------+------+-----------+--------------------+----+----------+-----+------+-----------+-----------+-------+--------------+------------+----------+----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create index for sex\n",
    "sex_indexer = StringIndexer(inputCol='sex', outputCol='sex_index')\n",
    "df = sex_indexer.fit(df).transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ! IMPORTANT ! For all index columns created, now transform them to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['row_names',\n",
       " 'pclass',\n",
       " 'survived',\n",
       " 'name',\n",
       " 'age',\n",
       " 'embarked',\n",
       " 'home_dest',\n",
       " 'room',\n",
       " 'ticket',\n",
       " 'boat',\n",
       " 'sex',\n",
       " 'class_index',\n",
       " 'age_imputed',\n",
       " 'new_age',\n",
       " 'embarked_index',\n",
       " 'room_imputed',\n",
       " 'room_categ',\n",
       " 'room_index',\n",
       " 'boat_index',\n",
       " 'sex_index']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall all the columns on the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all indexes to one_hot_encode vectors\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "class_encoder = OneHotEncoderEstimator(inputCols=['class_index'], outputCols=['class_vect'])\n",
    "df = class_encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_encoder = OneHotEncoderEstimator(inputCols=['embarked_index'], outputCols=['embarked_vect'])\n",
    "df = emb_encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "room_encoder = OneHotEncoderEstimator(inputCols=['room_index'], outputCols=['room_vect'])\n",
    "df = room_encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat_encoder = OneHotEncoderEstimator(inputCols=['boat_index'], outputCols=['boat_vect'])\n",
    "df = boat_encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_encoder = OneHotEncoderEstimator(inputCols=['sex_index'], outputCols=['sex_vect'])\n",
    "df = sex_encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['row_names',\n",
       " 'pclass',\n",
       " 'survived',\n",
       " 'name',\n",
       " 'age',\n",
       " 'embarked',\n",
       " 'home_dest',\n",
       " 'room',\n",
       " 'ticket',\n",
       " 'boat',\n",
       " 'sex',\n",
       " 'class_index',\n",
       " 'age_imputed',\n",
       " 'new_age',\n",
       " 'embarked_index',\n",
       " 'room_imputed',\n",
       " 'room_categ',\n",
       " 'room_index',\n",
       " 'boat_index',\n",
       " 'sex_index',\n",
       " 'class_vect',\n",
       " 'embarked_vect',\n",
       " 'room_vect',\n",
       " 'boat_vect',\n",
       " 'sex_vect']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final step before creating any ML model: Single vector with all transformed columns and columns created when imputing values\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-----------+-----------------+--------------+------------+----------+----------+----------+---------+-------------+-------------+-------------+---------------+-------------+\n",
      "|survived|class_index|age_imputed|          new_age|embarked_index|room_imputed|room_categ|room_index|boat_index|sex_index|   class_vect|embarked_vect|    room_vect|      boat_vect|     sex_vect|\n",
      "+--------+-----------+-----------+-----------------+--------------+------------+----------+----------+----------+---------+-------------+-------------+-------------+---------------+-------------+\n",
      "|       1|          1|          0|             29.0|           0.0|           0|         B|       1.0|      11.0|      1.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[1],[1.0])|(99,[11],[1.0])|    (1,[],[])|\n",
      "|       0|          1|          0|              2.0|           0.0|           0|         C|       0.0|      99.0|      1.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[0],[1.0])|     (99,[],[])|    (1,[],[])|\n",
      "|       0|          1|          0|             30.0|           0.0|           0|         C|       0.0|      48.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[0],[1.0])|(99,[48],[1.0])|(1,[0],[1.0])|\n",
      "|       0|          1|          0|             25.0|           0.0|           0|         C|       0.0|      99.0|      1.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[0],[1.0])|     (99,[],[])|    (1,[],[])|\n",
      "|       1|          1|          0|           0.9167|           0.0|           0|         C|       0.0|       5.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[0],[1.0])| (99,[5],[1.0])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             47.0|           0.0|           0|         E|       3.0|       3.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[3],[1.0])| (99,[3],[1.0])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             63.0|           0.0|           0|         D|       2.0|      13.0|      1.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[2],[1.0])|(99,[13],[1.0])|    (1,[],[])|\n",
      "|       0|          1|          0|             39.0|           0.0|           0|         A|       5.0|      99.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[5],[1.0])|     (99,[],[])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             58.0|           0.0|           0|         C|       0.0|      11.0|      1.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[0],[1.0])|(99,[11],[1.0])|    (1,[],[])|\n",
      "|       0|          1|          0|             71.0|           1.0|           1|      null|       7.0|      51.0|      0.0|(3,[1],[1.0])|(3,[1],[1.0])|    (7,[],[])|(99,[51],[1.0])|(1,[0],[1.0])|\n",
      "|       0|          1|          0|             47.0|           1.0|           1|      null|       7.0|      83.0|      0.0|(3,[1],[1.0])|(3,[1],[1.0])|    (7,[],[])|(99,[83],[1.0])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             19.0|           1.0|           1|      null|       7.0|       0.0|      1.0|(3,[1],[1.0])|(3,[1],[1.0])|    (7,[],[])| (99,[0],[1.0])|    (1,[],[])|\n",
      "|       1|          1|          1|31.19418104265403|           1.0|           0|         B|       1.0|       8.0|      1.0|(3,[1],[1.0])|(3,[1],[1.0])|(7,[1],[1.0])| (99,[8],[1.0])|    (1,[],[])|\n",
      "|       1|          1|          1|31.19418104265403|           0.0|           0|         A|       5.0|      15.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[5],[1.0])|(99,[15],[1.0])|(1,[0],[1.0])|\n",
      "|       0|          1|          1|31.19418104265403|           0.0|           1|      null|       7.0|      99.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|    (7,[],[])|     (99,[],[])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             50.0|           1.0|           0|         B|       1.0|       6.0|      1.0|(3,[1],[1.0])|(3,[1],[1.0])|(7,[1],[1.0])| (99,[6],[1.0])|    (1,[],[])|\n",
      "|       0|          1|          0|             24.0|           1.0|           0|         B|       1.0|      99.0|      0.0|(3,[1],[1.0])|(3,[1],[1.0])|(7,[1],[1.0])|     (99,[],[])|(1,[0],[1.0])|\n",
      "|       0|          1|          0|             36.0|           1.0|           0|         C|       0.0|      99.0|      0.0|(3,[1],[1.0])|(3,[1],[1.0])|(7,[0],[1.0])|     (99,[],[])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             37.0|           0.0|           0|         D|       2.0|       1.0|      0.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[2],[1.0])| (99,[1],[1.0])|(1,[0],[1.0])|\n",
      "|       1|          1|          0|             47.0|           0.0|           0|         D|       2.0|       1.0|      1.0|(3,[1],[1.0])|(3,[0],[1.0])|(7,[2],[1.0])| (99,[1],[1.0])|    (1,[],[])|\n",
      "+--------+-----------+-----------+-----------------+--------------+------------+----------+----------+----------+---------+-------------+-------------+-------------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first select only the labels and features we have created to this point\n",
    "df = df.select(['survived', 'class_index', 'age_imputed', 'new_age', 'embarked_index'\n",
    "               ,'room_imputed', 'room_categ', 'room_index', 'boat_index', 'sex_index'\n",
    "               ,'class_vect', 'embarked_vect', 'room_vect', 'boat_vect', 'sex_vect'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled features: ['class_vect', 'age_imputed', 'new_age', 'embarked_vect', 'room_imputed', 'room_vect', 'boat_vect', 'sex_vect']\n",
      "+--------------------+--------+\n",
      "|            features|survived|\n",
      "+--------------------+--------+\n",
      "|(116,[1,4,5,10,27...|       1|\n",
      "|(116,[1,4,5,9],[1...|       0|\n",
      "|(116,[1,4,5,9,64,...|       0|\n",
      "|(116,[1,4,5,9],[1...|       0|\n",
      "|(116,[1,4,5,9,21,...|       1|\n",
      "|(116,[1,4,5,12,19...|       1|\n",
      "|(116,[1,4,5,11,29...|       1|\n",
      "|(116,[1,4,5,14,11...|       0|\n",
      "|(116,[1,4,5,9,27]...|       1|\n",
      "|(116,[1,4,6,8,67,...|       0|\n",
      "|(116,[1,4,6,8,99,...|       0|\n",
      "|(116,[1,4,6,8,16]...|       1|\n",
      "|(116,[1,3,4,6,10,...|       1|\n",
      "|(116,[1,3,4,5,14,...|       1|\n",
      "|(116,[1,3,4,5,8,1...|       0|\n",
      "|(116,[1,4,6,10,22...|       1|\n",
      "|(116,[1,4,6,10,11...|       0|\n",
      "|(116,[1,4,6,9,115...|       0|\n",
      "|(116,[1,4,5,11,17...|       1|\n",
      "|(116,[1,4,5,11,17...|       1|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a single vector only with valid features (no indexes or labels)\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['class_vect', 'age_imputed', 'new_age', 'embarked_vect', 'room_imputed', 'room_vect', 'boat_vect', 'sex_vect'],\n",
    "    outputCol='features')\n",
    "\n",
    "final_df = assembler.transform(df)\n",
    "final_df = final_df.select('features', 'survived')\n",
    "\n",
    "print(\"Assembled features: ['class_vect', 'age_imputed', 'new_age', 'embarked_vect', 'room_imputed', 'room_vect', 'boat_vect', 'sex_vect']\")\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally!!!\n",
    "Now we can create our regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data with an 80/20 ratio\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "train_data, test_data = final_df.randomSplit([0.8, 0.2], seed=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "lr_titanic = LogisticRegression(featuresCol='features', labelCol='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with training_data\n",
    "lr_model = lr_titanic.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions with test_data\n",
    "lr_results = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evaluator for our model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       0.0|\n",
      "|       1|       1.0|\n",
      "|       1|       1.0|\n",
      "|       1|       1.0|\n",
      "|       1|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_results.select('survived', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = lr_eval.evaluate(lr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8607638888888888"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's a pretty good model.\n",
    "\n",
    "Now, let's create other different models and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to evaluate performance of Decision Trees, Random Forest and Gradient Boosting\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the 3 different models\n",
    "dtc = DecisionTreeClassifier(labelCol='survived', featuresCol='features')\n",
    "rfc = RandomForestClassifier(labelCol='survived', featuresCol='features')\n",
    "gbc = GBTClassifier(labelCol='survived', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the models with training data\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbc_model = gbc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions with test_data \n",
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbc_preds = gbc_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to evaluate our model we use again BinaryClassificationEvaluator\n",
    "binary_eval = BinaryClassificationEvaluator(labelCol='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- survived: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# taking a look at the schema of predictions, we see the resulting vectors available for evaluation\n",
    "dtc_preds.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: 0.3241666666666667\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Classifier:', binary_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.8504513888888889\n"
     ]
    }
   ],
   "source": [
    "# surprisingly, random forest perfomed worst than our logistic regression model\n",
    "print('Random Forest Classifier:', binary_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier: 0.8889236111111111\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting Classifier:', binary_eval.evaluate(gbc_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, Gradient Boosting Classifier turns out to be the best one among the 4 chosen models \n",
    "#### (Logistic Regression, Decision Trees, Random Forest, Gradient Boosting)\n",
    "\n",
    "As a final note, we should remember that we used the default parameters when creating the classification models.\n",
    "There are dozens of parameters we can start tuning in order to get a better score on each one of the models created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
